{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwWmWsm8T7O0lBwXYLUNiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cesaenv/buscaminas/blob/main/3_1_An%C3%A1lisisEstad%C3%ADsticoComparaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 3.1. Análisis estadístico comparativo entre modelos\n"
      ],
      "metadata": {
        "id": "29jWR8BwMmal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Dataset\n",
        "\n",
        "Antes de comenzar vamos a cargar las librerías que serán necesarias. Con respecto al notebook 1, habría que cargar numpy y pandas."
      ],
      "metadata": {
        "id": "52SVy08kh2Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "50rRg4c1h4va"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Seguiremos con el dataset train.csv. Un dataset que intenta predecir la actividad que estaba realizando un paciente a partir de distintos datos, los correspondientes a las columnas del dataset."
      ],
      "metadata": {
        "id": "ECn5ANECh6Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "TtEWgTolh6A7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestro dataset constituye a una recopilación de datos por cada paciente, por lo que vamos a describir cada una de las columnas (o datos). A continuación se muestra la descripción de las distintas características de este dataset.\n",
        "\n",
        "\n",
        "|  Name  | Description | Value Type |\n",
        "|---         |---       |---    \n",
        "| **SL** | Nivel de azúcar | Numerical |\n",
        "| **EEG** | Ratio monitor EEG | Numerical |\n",
        "| **BP** | Presión en sangre | Numerical |\n",
        "| **HR** | Ratio de latidos | Numerical |\n",
        "| **CIRCULATION** | Circulación de sangre | Numerical |\n",
        "\n",
        "Por otro lado, *ACTIVITY* es la predicción de la actividad que estaba realizando un paciente a partir de los anteriores datos. Es el que tenemos que predecir. Posibles valores:\n",
        "\n",
        "|  Valor  | Description\n",
        "|---         |---         \n",
        "| **0** | De pie |\n",
        "| **1** | Caminando |\n",
        "| **2** | Sentado |\n",
        "| **3** | Cayendo |\n",
        "| **4** | Con calambres |\n",
        "| **5** | Corriendo |"
      ],
      "metadata": {
        "id": "eSQ8Yg8Gh57r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar todos los conjuntos de la misma manera, tendré que evaluarlos con la misma partición del dataset. Por ello, realizamos ya la partición.\n",
        "\n",
        "Primero cargamos la librería:"
      ],
      "metadata": {
        "id": "AnwK3Moxiekb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Gz7ze2YTijSC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego tenemos que dividir a nuestro conjunto de entrenamiento en los propios datos y las correspondientes etiquetas:"
      ],
      "metadata": {
        "id": "e0aF28aRilma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X =  df.values[:,:-1]\n",
        "Y =  df.values[:,-1]"
      ],
      "metadata": {
        "id": "zXJhBnyxilW6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y luego hacemos la partición, asignando al conjunto test un 25%"
      ],
      "metadata": {
        "id": "R8QhxPzkilRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainData, testData, trainLabels, testLabels) = train_test_split(X,Y,test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "5E5PZTjKilMi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, importaremos aquí directamente las librerías que son necesarias para cada uno de los algoritmos de clasificación:"
      ],
      "metadata": {
        "id": "guJ3d2rpilIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#Árboles de decisión\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "#Regresión logística\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "#Redes neuronales\n",
        "from sklearn.linear_model import Perceptron #para el tipo de red neuronal Perceptron (el más sencillo)\n",
        "from sklearn.neural_network import MLPClassifier #para el tipo de red neuronal Perceptron pero multicapa\n",
        "#RandomSearch\n",
        "from scipy.stats import randint as sp_randint"
      ],
      "metadata": {
        "id": "J3OJisshilCa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bQO1k5-4ik6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, como en la realización del notebook me molestaban los warnings he decidido ignorarlos:"
      ],
      "metadata": {
        "id": "ocbSrHwLiRyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Ignorar todos los warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "byPhRBKMh527"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo último que vamos a ver en esta parte es cómo realizar un estudio estadístico basado en lo que vimos en clase, para ello utilizaremos la función `compare_methods` disponible en el módulo StatisticalAnalysis. Comienzo instalando este módulo usando `pip`."
      ],
      "metadata": {
        "id": "Hpf5W7NNhyxi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_c-9r5AnMLTQ",
        "outputId": "c29e3da7-bbd5-41aa-efc0-5797de77a039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting StatisticalAnalysis\n",
            "  Downloading StatisticalAnalysis-0.0.5.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: StatisticalAnalysis\n",
            "  Building wheel for StatisticalAnalysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for StatisticalAnalysis: filename=StatisticalAnalysis-0.0.5-py2.py3-none-any.whl size=13098 sha256=2cc28330b442b2d678216f905454b12b6a546ff4ef86425b5ee3be5852f877c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/db/95/26b1f6f0da09912e26583c42371b4ac0d4fd1a8348a8636b6b\n",
            "Successfully built StatisticalAnalysis\n",
            "Installing collected packages: StatisticalAnalysis\n",
            "Successfully installed StatisticalAnalysis-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install StatisticalAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estudio Estadístico"
      ],
      "metadata": {
        "id": "RgO5ijQ9i0p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from StatisticalAnalysis import compare_methods"
      ],
      "metadata": {
        "id": "CZWP-wn-Ml59"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizar este método debemos comenzar indicando los algoritmos a utilizar y las distribuciones de los hiperparámetros a optimizar. Vamos a utilizar los 5 modelos de la parte de Aprendizaje Supervisado vistos en 3. Comparativa de algoritmos: árboles de decisión, SVMs, KNN, Regresión logística y red neuronal, así que definimos estos modelos y los parámetros a optimizar."
      ],
      "metadata": {
        "id": "u43kfHWqhSgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Árbol de decisión\n",
        "clfTree = DecisionTreeClassifier(random_state=84)\n",
        "param_distTree = {\"min_samples_split\": sp_randint(3, 30)}\n",
        "# SVM\n",
        "clfSVC = SVC(random_state=84)\n",
        "param_distSVC = {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],'kernel': ['rbf'], 'class_weight':['balanced', None]}\n",
        "# KNN\n",
        "clfKNN = KNeighborsClassifier()\n",
        "param_distKNN = {'n_neighbors':sp_randint(3, 30)}\n",
        "# Regresión logística\n",
        "clfLR = LogisticRegression(random_state=84)\n",
        "param_distLR = {'C': [0.1,0.5,1, 10, 100, 1000]}\n",
        "# Red neuronal\n",
        "clfMLP = MLPClassifier(random_state=84)\n",
        "param_distMLP = {'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "                 'alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "                 'hidden_layer_sizes': [(5,2), (3,3,3), (5,3,2), (5,4,3,2)],\n",
        "                 'momentum': [0.9, 0.95, 0.99]}"
      ],
      "metadata": {
        "id": "_LrY4yTwhThZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos tres listas que contendrán respectivamente:"
      ],
      "metadata": {
        "id": "Bq9bTclUjJ9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Los algoritmos\n",
        "listAlgorithms = [clfTree,clfSVC,clfKNN,clfLR,clfMLP]\n",
        "#Los parámetros a optimizar\n",
        "listParams = [param_distTree,param_distSVC,param_distKNN,param_distLR,param_distMLP]\n",
        "#Los nombres de los algoritmos\n",
        "listNames = [\"Arbol\", \"SVM\", \"KNN\", \"LR\", \"MLP\"]"
      ],
      "metadata": {
        "id": "VaHRUmhZhnpE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invocamos a la función `compare_methods` pasándole el dataset completo, el conjunto de etiquetas completo, las tres listas definidas anteriormente, y la métrica. Los valores válidos\n",
        "para la métrica son accuracy, precision, recall, f1 o auroc. Al invocar a la función anterior se producirá un informe de resultados."
      ],
      "metadata": {
        "id": "bQh3qZLtjUFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estudio estadístico con métrica accuracy"
      ],
      "metadata": {
        "id": "Kf0rxyJMkJyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_methods(X,Y,listAlgorithms,listParams,listNames,metric='accuracy')\n",
        "#función dada gracias a:  from StatisticalAnalysis import compare_methods"
      ],
      "metadata": {
        "id": "e8B-TEvljRI6",
        "outputId": "4d5b9988-c21e-4af8-f086-064f9f089d1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the multiclass problem, only accuracy can be used as metric\n",
            "In the multiclass problem, only accuracy can be used as metric\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qNnekuuxkU8b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}